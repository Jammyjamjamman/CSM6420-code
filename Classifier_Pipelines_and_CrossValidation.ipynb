{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"train.csv\", index_col=None)\n",
    "# Split values and class for convenience.\n",
    "X, Y = train.iloc[:,1:], train[\"Class\"]\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Pipelines\n",
    "### Build a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Random Forest, Support Vector Machine and Bernoulli Niave Bayes classifier pipelines.\n",
    "#\n",
    "# Based on the code from the following source:\n",
    "########################################\n",
    "# Title: Tutorial 3-Titanic5 Building Pipelines and Model Comparison\n",
    "# Author: Chuan Lu\n",
    "# Date: 06/04/2017\n",
    "# Code Version: 47c58c0\n",
    "# Available: https://github.com/aberML/CSM6420/\n",
    "#######################################\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "scaler = StandardScaler()\n",
    "anova_filter = SelectKBest(f_regression)\n",
    "\n",
    "# Random Forest Classifier.\n",
    "clf = RandomForestClassifier()\n",
    "pipeline_rf = Pipeline([\n",
    "    ('anova', anova_filter),\n",
    "    ('rf', clf)\n",
    "])\n",
    "\n",
    "# Support Vector Machine.\n",
    "clf = SVC(probability=True)\n",
    "pipeline_svm = Pipeline([\n",
    "        ('scale', scaler), \n",
    "        ('anova', anova_filter), \n",
    "        ('svc', clf)\n",
    "])\n",
    "\n",
    "# Bernoulli (true or false) Niave Bayes Classifier.\n",
    "clf = BernoulliNB()\n",
    "pipeline_bnb = Pipeline([\n",
    "    ('anova', anova_filter),\n",
    "    ('bnb', clf)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Parameters for the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using 8 k-fold cross-validation.\n",
    "kfolds = 8\n",
    "\n",
    "# Set parameters for grid searches.\n",
    "pipeline_dict = {'rf': pipeline_rf, 'svm': pipeline_svm, 'bnb': pipeline_bnb} \n",
    "parameter_grid_dict = {}\n",
    "parameter_grid_dict['rf'] = {\n",
    "            'anova__k': [10, 100, 'all'],\n",
    "            'rf__n_estimators': [10, 100, 1000],\n",
    "            'rf__max_depth': [5, 10, 50, 100, None],\n",
    "        }\n",
    "\n",
    "parameter_grid_dict['svm'] = {\n",
    "            'anova__k': [5, 100, 500, 'all'],\n",
    "            'svc__kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "            'svc__C': [0.01, 0.1, 1, 10],\n",
    "            'svc__gamma': [0, 0.1, 1]\n",
    "        }\n",
    "\n",
    "parameter_grid_dict['bnb'] = {\n",
    "            'anova__k': [1, 5, 10, 'all'],\n",
    "            'bnb__alpha': np.linspace(0,1,11),\n",
    "            'bnb__fit_prior': [True, False],\n",
    "        }\n",
    "\n",
    "grid_results = {}\n",
    "for alg in ['rf', 'svm', 'bnb']:\n",
    "    pipeline = pipeline_dict[alg]\n",
    "    parameter_grid = parameter_grid_dict[alg]    \n",
    "    grid_search = GridSearchCV(pipeline, parameter_grid, cv=kfolds, verbose=3, n_jobs=8)\n",
    "    grid_search.fit(X, Y)\n",
    "\n",
    "    sorted(grid_search.grid_scores_, key=lambda x: x.mean_validation_score)\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    grid_results[alg] = grid_search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of the grid search results \n",
    "for alg in grid_results:\n",
    "    grid_search = grid_results[alg]\n",
    "    sorted(grid_search.grid_scores_, key=lambda x: x.mean_validation_score)\n",
    "    print('Best accuracy for %s :' % alg)\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Best accuracy for rf :\n",
    "0.871\n",
    "{'anova__k': 100, 'rf__max_depth': 100, 'rf__n_estimators': 1000}\n",
    "Best accuracy for svm :\n",
    "0.841\n",
    "{'anova__k': 100, 'svc__C': 0.01, 'svc__gamma': 0.1, 'svc__kernel': 'poly'}\n",
    "Best accuracy for bnb :\n",
    "0.864\n",
    "{'anova__k': 'all', 'bnb__alpha': 1.0, 'bnb__fit_prior': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_params = {}\n",
    "optimal_params['rf'] = {'anova__k': 100, 'rf__max_depth': 100, 'rf__n_estimators': 1000}\n",
    "optimal_params['svm'] = {'anova__k': 100, 'svc__C': 0.01, 'svc__gamma': 0.1, 'svc__kernel': 'poly'}\n",
    "optimal_params['bnb'] = {'anova__k': 'all', 'bnb__alpha': 1.0, 'bnb__fit_prior': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curves and AUC values code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# ROC plot and AUC statistic, based on the code from the following source:\n",
    "########################################\n",
    "# Title: Tutorial 3-Titanic3 Cross-validation with ROC analysis\n",
    "# Author: Chuan Lu\n",
    "# Date: 06/04/2017\n",
    "# Code Version: 47c58c0\n",
    "# Available: https://github.com/aberML/CSM6420/\n",
    "########################################\n",
    "\n",
    "# (Hacked together, but does the job ;-) )\n",
    "mean_acc = 0.0\n",
    "mean_auc = 0.0\n",
    "all_tpr = []\n",
    "all_acc = []\n",
    "all_auc = []\n",
    "\n",
    "i=0\n",
    "\n",
    "def ROC_AUC(y_test, y_prob):\n",
    "    global i, mean_acc, mean_auc, all_tpr, all_acc, all_auc\n",
    "    i += 1\n",
    "    # Get prediction on class label from the model\n",
    "    y_prediction = np.around(y_prob, decimals=0)\n",
    "    \n",
    "    # Get probability output from the model\n",
    "    acc = np.sum(y_test == y_prediction)*1./len(y_test)\n",
    "    print(\"Prediction accuracy:\", acc)\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(\"Area under ROC curve (AUC):\", roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))    \n",
    "    all_acc.append(acc)\n",
    "    all_auc.append(roc_auc)\n",
    "    return acc, roc_auc\n",
    "\n",
    "def display_plot(title = 'Receiver operating characteristic example'):\n",
    "    global i, mean_acc, mean_auc, all_tpr, all_acc, all_auc\n",
    "    plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6))\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    all_acc=np.asarray(all_acc)\n",
    "    all_auc=np.asarray(all_auc)\n",
    "    print(all_acc)\n",
    "    # print 95% C.I. for both accuracy and AUC based on CV\n",
    "    print(\"Mean Accuracy: %0.3f (+/- %0.3f)\" % (all_acc.mean(), all_acc.std() * 1.96))\n",
    "    print(all_auc)\n",
    "    print(\"Mean AUC: %0.3f (+/- %0.3f)\" % (all_auc.mean(), all_auc.std() * 1.96))\n",
    "    \n",
    "    # Reset values for re-use.\n",
    "    mean_acc = 0.0\n",
    "    mean_auc = 0.0\n",
    "    all_tpr = []\n",
    "    all_acc = []\n",
    "    all_auc = []\n",
    "\n",
    "    i=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross-Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold as SKFold\n",
    "\n",
    "random_seed = 1234\n",
    "scv = SKFold(y=Y, n_folds=kfolds, random_state=random_seed)\n",
    "\n",
    "acc_clfs = pd.DataFrame()\n",
    "auc_clfs = pd.DataFrame()\n",
    "\n",
    "for alg, title in [('rf', \"Random Forest\"),\n",
    "                   ('svm', \"Support Vector Machine\"),\n",
    "                   ('bnb', \"Bernoulli Niave Bayes\")]:\n",
    "    pipeline = pipeline_dict[alg]\n",
    "    params = optimal_params[alg]\n",
    "    plt.figure()\n",
    "    \n",
    "    best_acc = best_auc = 0\n",
    "    \n",
    "    for training_set, test_set in scv:  \n",
    "        X_train = X.iloc[training_set]\n",
    "        y_train = Y.iloc[training_set]\n",
    "        X_test = X.iloc[test_set]\n",
    "        y_test = Y.iloc[test_set]\n",
    "        print(\"Shape of training:\")\n",
    "        print(\"X:\", X_train.shape, \"y:\", y_train.shape)\n",
    "        print(\"Shape of testing:\")\n",
    "        print(\"X:\", X_test.shape, \"y:\", y_test.shape)\n",
    "\n",
    "        pipeline.set_params(**params)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = pipeline.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        # Plot.\n",
    "        acc, roc_auc = ROC_AUC(y_test, y_pred)\n",
    "        \n",
    "        # Crudely assume the best model has the highest combined acc and ROC_AUC.\n",
    "        if acc + roc_auc > best_auc + best_acc:\n",
    "            # Save predictions for the best result.\n",
    "            best_acc = acc\n",
    "            best_auc = roc_auc\n",
    "            \n",
    "            # Prepare test predictions for submission.\n",
    "            test = pd.read_csv(\"test.csv\")\n",
    "            X_test, Id = test.iloc[:,1:], test[\"TestId\"]\n",
    "\n",
    "            Y_pred = pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "            pred_df = pd.DataFrame(Id)\n",
    "            pred_df = pred_df.join(pd.DataFrame({\"PredictedScore\": Y_pred}))\n",
    "            pred_df.to_csv(\"pred\"+alg+\".csv\", index = False)\n",
    "    \n",
    "    acc_clfs[alg] = np.asarray(all_acc)\n",
    "    auc_clfs[alg] = np.asarray(all_auc)\n",
    "    display_plot(title + \" Receiver Operating Characteristic\")\n",
    "    plt.savefig(\"ROC_\" + alg + \".pdf\")\n",
    "    \n",
    "acc_clfs.plot(kind='box', title='Accuracy from 8-fold CV')\n",
    "plt.savefig(\"acc.pdf\")\n",
    "auc_clfs.plot(kind='box', title='AUC from 8-fold CV')\n",
    "plt.savefig(\"auc.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF:\n",
    "Mean Accuracy: 0.869 (+/- 0.065)\n",
    "Mean AUC: 0.877 (+/- 0.081)\n",
    "SVM:\n",
    "Mean Accuracy: 0.841 (+/- 0.037)\n",
    "Mean AUC: 0.846 (+/- 0.071)\n",
    "BNB:\n",
    "Mean Accuracy: 0.864 (+/- 0.057)\n",
    "Mean AUC: 0.877 (+/- 0.089)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python:  sys.version_info(major=3, minor=6, micro=5, releaselevel='final', serial=0)\n",
      "Pandas:  0.22.0\n",
      "Sklearn:  0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "print('Python: ', sys.version_info)\n",
    "print('Pandas: ', pd.__version__)\n",
    "print('Sklearn: ', sklearn.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
